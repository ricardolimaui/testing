{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Welcome to the Open City Toolkit Developer Corner! This website provides ample information about re-use of resources of the Open City Toolkit (OCT) for software development purposes. It includes short installation guides for different development environments (e.g., node, bower, mkdocs), as well as different code snippets useful for data collection, storage, retrieval, analysis and visualization. Please check our menu on the left hand side for further information. Enjoy!","title":"Home"},{"location":"#welcome","text":"Welcome to the Open City Toolkit Developer Corner! This website provides ample information about re-use of resources of the Open City Toolkit (OCT) for software development purposes. It includes short installation guides for different development environments (e.g., node, bower, mkdocs), as well as different code snippets useful for data collection, storage, retrieval, analysis and visualization. Please check our menu on the left hand side for further information. Enjoy!","title":"Welcome"},{"location":"about/contributors/","text":"Contributors \u00b6 Devanjan Bhattacharya Auriol Degbelo aurideg Carlos Granell Markus Konkol MarkusKonk Nemanja Kostic NemanjaKostic Samuel Navas samuelnavas Nicholas Schiestel nicho90 Sergi Trilles sergitrilles Jonas Wissing JonasWissing","title":"Contributors"},{"location":"about/contributors/#contributors","text":"Devanjan Bhattacharya Auriol Degbelo aurideg Carlos Granell Markus Konkol MarkusKonk Nemanja Kostic NemanjaKostic Samuel Navas samuelnavas Nicholas Schiestel nicho90 Sergi Trilles sergitrilles Jonas Wissing JonasWissing","title":"Contributors"},{"location":"about/licenses/","text":"Using our data \u00b6 Unless otherwise stated, our data is distributed under the CC0 license . You are free to re-use it and republish it, without restriction. Using our code \u00b6 Unless otherwise stated, our code is distributed under the Apache (v2) license . The code of the Open City Toolkit is available on GitHub.","title":"Licenses"},{"location":"about/licenses/#using-our-data","text":"Unless otherwise stated, our data is distributed under the CC0 license . You are free to re-use it and republish it, without restriction.","title":"Using our data"},{"location":"about/licenses/#using-our-code","text":"Unless otherwise stated, our code is distributed under the Apache (v2) license . The code of the Open City Toolkit is available on GitHub.","title":"Using our code"},{"location":"about/repositories/","text":"Repositories \u00b6 Open-City-Toolkit The OCT is a a collection of tools, processes, specifications and guidelines to empower citizens to participate in and shape the future of their cities and deliver services based on open data that are useful for citizens, businesses and governing bodies alike. https://github.com/geo-c/Open-City-Toolkit.git Dev-Corner Project-Documentation written in Markdown with MkDocs If you want to contribute to this site, you can find the installation and contribution-guideline here https://github.com/geo-c/Dev-Corner.git","title":"Repositories"},{"location":"about/repositories/#repositories","text":"Open-City-Toolkit The OCT is a a collection of tools, processes, specifications and guidelines to empower citizens to participate in and shape the future of their cities and deliver services based on open data that are useful for citizens, businesses and governing bodies alike. https://github.com/geo-c/Open-City-Toolkit.git Dev-Corner Project-Documentation written in Markdown with MkDocs If you want to contribute to this site, you can find the installation and contribution-guideline here https://github.com/geo-c/Dev-Corner.git","title":"Repositories"},{"location":"data/analysis/","text":"Analysis \u00b6 To-Do","title":"Analysis"},{"location":"data/analysis/#analysis","text":"To-Do","title":"Analysis"},{"location":"data/collection/","text":"Collection \u00b6 To-Do","title":"Collection"},{"location":"data/collection/#collection","text":"To-Do","title":"Collection"},{"location":"data/retrieval/","text":"In this section, different snippets are provided to retrieve datasets or packages CKAN. Three different operations are detailed in order to retrieve the data. The first operation, Datastore_search , uses the DataStore API. The DataStore API offers the hability to search and filter data without the need to download the entire file first. The other two operations, Reatrive a specific resource and Reatrive all resources from a group , use the general API provided by CKAN to interact with CKAN sites and their data. Before you use the following snippets, please make sure, that you read the terms of use of our data.","title":"Retrieval"},{"location":"data/storage/","text":"In this section, different snippets are provided to create/store datasets or packages into CKAN. Four different operations are detailed using the DataStore API. The DataStore API offers the hability to insert a new data, or existing data can be updated or deleted. You can also add a new column to an existing table even if the DataStore resource already contains some data. These four operations are: Datastore_create , Datastore_delete , Datastore_upsert and Package_create . Before you use the following snippets, please make sure, that you read the terms of use of our data.","title":"Storage"},{"location":"data/visualization/","text":"R snippets to access Socrata-based open data servers (Example 1) \u00b6 Description \u00b6 This example creates a map viewer by pulling a dataset from the NYC\u2019s Open Data Portal containing a list of NYC Health and Hospitals Corporation Facilities Code \u00b6 library(\"RSocrata\") # reading and writing to and from Socrata # human-readable URL url <- \"https://data.cityofnewyork.us/Health/NYC-Health-and-Hospitals-Corporation-Facilities/ymhw-9cz9\" df.hhc <- read.socrata(url) # type conversion df.hhc$Facility.Name <- as.character(df.hhc$Facility.Name) df.hhc$Cross.Streets <- as.character(df.hhc$Cross.Streets) df.hhc$Phone <- as.character(df.hhc$Phone) df.hhc$Location.1 <- as.character(df.hhc$Location.1) # data parsing to extract location extract_location <- function(x) return <- unlist(gsub(\"[\\\\(\\\\)]\", \"\", regmatches(x, gregexpr(\"\\\\(.*?\\\\)\", x))[[1]])) extract_latlon <- function(x) return (unlist(strsplit(x, \", \"))) extract_lat <- function(x) return (as.numeric(x[1])) extract_lon <- function(x) return (as.numeric(x[2])) location <- lapply(df.hhc$Location.1, function(x) extract_location(x)) location <- lapply(location, function(x) extract_latlon(x[[1]])) df.hhc$Lat <- sapply(location, function(x) extract_lat(x)) df.hhc$Lon <- sapply(location, function(x) extract_lon(x)) # add the leaflet library to your script library(leaflet) # Similar to addCircleMarkers(addTitle(leaflet())) leaflet(data = df.hhc) %>% addTiles() %>% addCircleMarkers( ~Lon, ~Lat, popup = ~as.character(Facility.Name), clusterOptions = markerClusterOptions()) R snippets to access Socrata-based open data servers (Example 2) \u00b6 Description \u00b6 This example creates a map viewer (clustering) by pulling a dataset from the NYC\u2019s Open Data Portal containing a list of NYC Health and Hospitals Corporation Facilities. Code \u00b6 library(\"RSocrata\") # reading and writing to and from Socrata # human-readable URL url <- \"https://data.cityofnewyork.us/Health/NYC-Health-and-Hospitals-Corporation-Facilities/ymhw-9cz9\" df.hhc <- read.socrata(url) # type conversion df.hhc$Facility.Name <- as.character(df.hhc$Facility.Name) df.hhc$Cross.Streets <- as.character(df.hhc$Cross.Streets) df.hhc$Phone <- as.character(df.hhc$Phone) df.hhc$Location.1 <- as.character(df.hhc$Location.1) # data parsing to extract location extract_location <- function(x) return <- unlist(gsub(\"[\\\\(\\\\)]\", \"\", regmatches(x, gregexpr(\"\\\\(.*?\\\\)\", x))[[1]])) extract_latlon <- function(x) return (unlist(strsplit(x, \", \"))) extract_lat <- function(x) return (as.numeric(x[1])) extract_lon <- function(x) return (as.numeric(x[2])) location <- lapply(df.hhc$Location.1, function(x) extract_location(x)) location <- lapply(location, function(x) extract_latlon(x[[1]])) df.hhc$Lat <- sapply(location, function(x) extract_lat(x)) df.hhc$Lon <- sapply(location, function(x) extract_lon(x)) # add the leaflet library to your script library(leaflet) # Create a palette that maps factor levels to colors pal <- colorFactor(c(\"navy\", \"red\", \"orange\", \"purple\"), domain = df.hhc$Facility.Type) map <- leaflet(data = df.hhc) %>% addTiles(group = \"OSM (default)\") %>% addProviderTiles(\"Stamen.Toner\", group = \"Toner\") %>% addProviderTiles(\"Stamen.TonerLite\", group = \"Toner Lite\") %>% addCircleMarkers( ~Lon, ~Lat, color = ~pal(Facility.Type), stroke = FALSE, fillOpacity = 0.5, popup= ~as.character(Facility.Name), group = \"HHC\" ) %>% # Layers control addLayersControl( baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"), overlayGroups = c(\"HHC\"), options = layersControlOptions(collapsed = FALSE) ) map R snippets to access CKAN-based open data servers \u00b6 Description \u00b6 This example is pulling a dataset from the CivicData Open Data Portal containing 2014 Salt Lake City crime incidents. Code \u00b6 url <- \"http://civicdataprod1.cloudapp.net/storage/f/2014-07-07T16%3A17%3A25.958Z/2014.csv\" crimes <- read.csv(file=url,head=TRUE,sep=\",\") nrow(crimes) head(crimes) str(crimes) # type conversion crimes$Address <- as.character(crimes$Address) crimes$Description <- as.character(crimes$Description) str(crimes) # levels to groups data table(crimes$Type) library(leaflet) num_colors <- length(levels(crimes$Type)) pal <- colorFactor(topo.colors(num_colors), crimes$Type) map <- leaflet(data = crimes) %>% addTiles(group = \"OSM (default)\") %>% addProviderTiles(\"Stamen.Toner\", group = \"Toner\") %>% addProviderTiles(\"Stamen.TonerLite\", group = \"Toner Lite\") %>% addCircleMarkers( ~Longitude, ~Latitude, color = ~pal(Type), stroke = FALSE, fillOpacity = 0.5, popup= ~as.character(Description), group = \"Crimes\" ) %>% # Layers control addLayersControl( baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"), overlayGroups = c(\"Crimes\"), options = layersControlOptions(collapsed = FALSE) ) map","title":"Visualization"},{"location":"data/visualization/#r-snippets-to-access-socrata-based-open-data-servers-example-1","text":"","title":"R snippets to access Socrata-based open data servers (Example 1)"},{"location":"data/visualization/#description","text":"This example creates a map viewer by pulling a dataset from the NYC\u2019s Open Data Portal containing a list of NYC Health and Hospitals Corporation Facilities","title":"Description"},{"location":"data/visualization/#code","text":"library(\"RSocrata\") # reading and writing to and from Socrata # human-readable URL url <- \"https://data.cityofnewyork.us/Health/NYC-Health-and-Hospitals-Corporation-Facilities/ymhw-9cz9\" df.hhc <- read.socrata(url) # type conversion df.hhc$Facility.Name <- as.character(df.hhc$Facility.Name) df.hhc$Cross.Streets <- as.character(df.hhc$Cross.Streets) df.hhc$Phone <- as.character(df.hhc$Phone) df.hhc$Location.1 <- as.character(df.hhc$Location.1) # data parsing to extract location extract_location <- function(x) return <- unlist(gsub(\"[\\\\(\\\\)]\", \"\", regmatches(x, gregexpr(\"\\\\(.*?\\\\)\", x))[[1]])) extract_latlon <- function(x) return (unlist(strsplit(x, \", \"))) extract_lat <- function(x) return (as.numeric(x[1])) extract_lon <- function(x) return (as.numeric(x[2])) location <- lapply(df.hhc$Location.1, function(x) extract_location(x)) location <- lapply(location, function(x) extract_latlon(x[[1]])) df.hhc$Lat <- sapply(location, function(x) extract_lat(x)) df.hhc$Lon <- sapply(location, function(x) extract_lon(x)) # add the leaflet library to your script library(leaflet) # Similar to addCircleMarkers(addTitle(leaflet())) leaflet(data = df.hhc) %>% addTiles() %>% addCircleMarkers( ~Lon, ~Lat, popup = ~as.character(Facility.Name), clusterOptions = markerClusterOptions())","title":"Code"},{"location":"data/visualization/#r-snippets-to-access-socrata-based-open-data-servers-example-2","text":"","title":"R snippets to access Socrata-based open data servers (Example 2)"},{"location":"data/visualization/#description_1","text":"This example creates a map viewer (clustering) by pulling a dataset from the NYC\u2019s Open Data Portal containing a list of NYC Health and Hospitals Corporation Facilities.","title":"Description"},{"location":"data/visualization/#code_1","text":"library(\"RSocrata\") # reading and writing to and from Socrata # human-readable URL url <- \"https://data.cityofnewyork.us/Health/NYC-Health-and-Hospitals-Corporation-Facilities/ymhw-9cz9\" df.hhc <- read.socrata(url) # type conversion df.hhc$Facility.Name <- as.character(df.hhc$Facility.Name) df.hhc$Cross.Streets <- as.character(df.hhc$Cross.Streets) df.hhc$Phone <- as.character(df.hhc$Phone) df.hhc$Location.1 <- as.character(df.hhc$Location.1) # data parsing to extract location extract_location <- function(x) return <- unlist(gsub(\"[\\\\(\\\\)]\", \"\", regmatches(x, gregexpr(\"\\\\(.*?\\\\)\", x))[[1]])) extract_latlon <- function(x) return (unlist(strsplit(x, \", \"))) extract_lat <- function(x) return (as.numeric(x[1])) extract_lon <- function(x) return (as.numeric(x[2])) location <- lapply(df.hhc$Location.1, function(x) extract_location(x)) location <- lapply(location, function(x) extract_latlon(x[[1]])) df.hhc$Lat <- sapply(location, function(x) extract_lat(x)) df.hhc$Lon <- sapply(location, function(x) extract_lon(x)) # add the leaflet library to your script library(leaflet) # Create a palette that maps factor levels to colors pal <- colorFactor(c(\"navy\", \"red\", \"orange\", \"purple\"), domain = df.hhc$Facility.Type) map <- leaflet(data = df.hhc) %>% addTiles(group = \"OSM (default)\") %>% addProviderTiles(\"Stamen.Toner\", group = \"Toner\") %>% addProviderTiles(\"Stamen.TonerLite\", group = \"Toner Lite\") %>% addCircleMarkers( ~Lon, ~Lat, color = ~pal(Facility.Type), stroke = FALSE, fillOpacity = 0.5, popup= ~as.character(Facility.Name), group = \"HHC\" ) %>% # Layers control addLayersControl( baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"), overlayGroups = c(\"HHC\"), options = layersControlOptions(collapsed = FALSE) ) map","title":"Code"},{"location":"data/visualization/#r-snippets-to-access-ckan-based-open-data-servers","text":"","title":"R snippets to access CKAN-based open data servers"},{"location":"data/visualization/#description_2","text":"This example is pulling a dataset from the CivicData Open Data Portal containing 2014 Salt Lake City crime incidents.","title":"Description"},{"location":"data/visualization/#code_2","text":"url <- \"http://civicdataprod1.cloudapp.net/storage/f/2014-07-07T16%3A17%3A25.958Z/2014.csv\" crimes <- read.csv(file=url,head=TRUE,sep=\",\") nrow(crimes) head(crimes) str(crimes) # type conversion crimes$Address <- as.character(crimes$Address) crimes$Description <- as.character(crimes$Description) str(crimes) # levels to groups data table(crimes$Type) library(leaflet) num_colors <- length(levels(crimes$Type)) pal <- colorFactor(topo.colors(num_colors), crimes$Type) map <- leaflet(data = crimes) %>% addTiles(group = \"OSM (default)\") %>% addProviderTiles(\"Stamen.Toner\", group = \"Toner\") %>% addProviderTiles(\"Stamen.TonerLite\", group = \"Toner Lite\") %>% addCircleMarkers( ~Longitude, ~Latitude, color = ~pal(Type), stroke = FALSE, fillOpacity = 0.5, popup= ~as.character(Description), group = \"Crimes\" ) %>% # Layers control addLayersControl( baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"), overlayGroups = c(\"Crimes\"), options = layersControlOptions(collapsed = FALSE) ) map","title":"Code"},{"location":"data/retrieval/datastore-search/","text":"Datastore_search \u00b6 Parameters \u00b6 resource_id (string) \u2013 id or alias of the resource to be searched against filters (dictionary) \u2013 matching conditions to select, e.g {\"key1\": \"a\", \"key2\": \"b\"} (optional) q (string) \u2013 full text query (optional) plain (boolean) \u2013 treat as plain text query (optional, default: true ) language (string) \u2013 language of the full text query (optional, default: \"english\" ) limit (integer) \u2013 maximum number of rows to return (optional, default: 100 ) offset (integer) \u2013 offset this number of rows (optional) fields (list or comma separated string) \u2013 fields to return (optional, default: all fields in original order) sort (string) \u2013 comma separated field names with ordering e.g.: \"fieldname1, fieldname2 desc\" Javascript \u00b6 <script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var resourceId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; var nfilters = {\"region\": 'KEN'}; var search = client.action('datastore_search', { resource_id: resourceId, filters: nfilters }, function(err) { if (err) console.log(err); console.log('All done'); }); </script> Python \u00b6 #!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = 'c123ba85-41f9-4a04-80f5-a26368ba9204' ckan = ckanapi.RemoteCKAN(remote, apikey) filters = {\"region\": \"KEN\"} data = ckan.action.datastore_search(resource_id=resource_id, filters=filters) for record in data['records']: print 'region: {x}, value: {y}'.format(x=record['region'], y=record['value'])","title":"Datastore_search"},{"location":"data/retrieval/datastore-search/#datastore_search","text":"","title":"Datastore_search"},{"location":"data/retrieval/datastore-search/#parameters","text":"resource_id (string) \u2013 id or alias of the resource to be searched against filters (dictionary) \u2013 matching conditions to select, e.g {\"key1\": \"a\", \"key2\": \"b\"} (optional) q (string) \u2013 full text query (optional) plain (boolean) \u2013 treat as plain text query (optional, default: true ) language (string) \u2013 language of the full text query (optional, default: \"english\" ) limit (integer) \u2013 maximum number of rows to return (optional, default: 100 ) offset (integer) \u2013 offset this number of rows (optional) fields (list or comma separated string) \u2013 fields to return (optional, default: all fields in original order) sort (string) \u2013 comma separated field names with ordering e.g.: \"fieldname1, fieldname2 desc\"","title":"Parameters"},{"location":"data/retrieval/datastore-search/#javascript","text":"<script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var resourceId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; var nfilters = {\"region\": 'KEN'}; var search = client.action('datastore_search', { resource_id: resourceId, filters: nfilters }, function(err) { if (err) console.log(err); console.log('All done'); }); </script>","title":"Javascript"},{"location":"data/retrieval/datastore-search/#python","text":"#!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = 'c123ba85-41f9-4a04-80f5-a26368ba9204' ckan = ckanapi.RemoteCKAN(remote, apikey) filters = {\"region\": \"KEN\"} data = ckan.action.datastore_search(resource_id=resource_id, filters=filters) for record in data['records']: print 'region: {x}, value: {y}'.format(x=record['region'], y=record['value'])","title":"Python"},{"location":"data/retrieval/retrieve-from-ckangroup/","text":"Retrieving all resources from a group \u00b6 This snippet is useful to retrieve all resources belonging to one of four groups of the ckan instance: data service app guideline //var uri = \"YOUR CKAN URI\" var uri = \"http://giv-oct.uni-muenster.de:5000\"; //var id = \"YOUR GROUP ID\" var id = \"apps\"; $.ajax({ url: uri+\"/api/3/action/package_search?q=groups:\"+id+\"&rows=3000\", dataType:\"json\", async:true, success: function(json){ console.log(json); //PARSE JSON } });","title":"Retrieve from ckan group"},{"location":"data/retrieval/retrieve-from-ckangroup/#retrieving-all-resources-from-a-group","text":"This snippet is useful to retrieve all resources belonging to one of four groups of the ckan instance: data service app guideline //var uri = \"YOUR CKAN URI\" var uri = \"http://giv-oct.uni-muenster.de:5000\"; //var id = \"YOUR GROUP ID\" var id = \"apps\"; $.ajax({ url: uri+\"/api/3/action/package_search?q=groups:\"+id+\"&rows=3000\", dataType:\"json\", async:true, success: function(json){ console.log(json); //PARSE JSON } });","title":"Retrieving all resources from a group"},{"location":"data/retrieval/retrieve-specific-resource/","text":"Retrieving a specific resource \u00b6 This snippet is useful to retrieve a specific resource from our ckan instance. //var uri = \"YOUR CKAN URI\" var uri = \"http://giv-oct.uni-muenster.de:5000\"; //var id = \"YOUR RESOURCE ID\" var id = \"abc-ancientwoods\"; $.ajax({ url: uri+\"/api/3/action/package_show?id=\"+id, dataType:\"json\", async:true, success: function(json){ console.log(json); //PARSE JSON } });","title":"Retrieve a resource"},{"location":"data/retrieval/retrieve-specific-resource/#retrieving-a-specific-resource","text":"This snippet is useful to retrieve a specific resource from our ckan instance. //var uri = \"YOUR CKAN URI\" var uri = \"http://giv-oct.uni-muenster.de:5000\"; //var id = \"YOUR RESOURCE ID\" var id = \"abc-ancientwoods\"; $.ajax({ url: uri+\"/api/3/action/package_show?id=\"+id, dataType:\"json\", async:true, success: function(json){ console.log(json); //PARSE JSON } });","title":"Retrieving a specific resource"},{"location":"data/storage/datastore-create/","text":"Datastore_create \u00b6 Parameters \u00b6 resource_id (string) \u2013 resource id that the data is going to be stored against. force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource resource (dictionary) \u2013 resource dictionary that is passed to resource_create() . Use instead of resource_id (optional) aliases (list or comma separated string) \u2013 names for read only aliases of the resource. (optional) fields (list of dictionaries) \u2013 fields/columns and their extra metadata. (optional) records (list of dictionaries) \u2013 the data, e.g.: [{\"dob\": \"2005\", \"some_stuff\": [\"a\", \"b\"]}] (optional) primary_key (list or comma separated string) \u2013 fields that represent a unique key (optional) indexes (list or comma separated string) \u2013 indexes on table (optional) Javascript \u00b6 <script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var nfields = [ {'id': 'dataset_id', 'type': 'text'}, {'id': 'indicator_id', 'type': 'text'}, {'id': 'region', 'type': 'text'}, {'id': 'period', 'type': 'int'}, {'id': 'value', 'type': 'float'} ]; var data = [ { 'indicator_id': 'Population', 'dataset_id': 'acled', 'region': 'ITA', 'value': '5000000', 'period': '2016' } ]; var resource = { \"package_id\": \"packagetest\", \"format\": \"CSV\", \"name\": \"NameExample2\" }; client.action('datastore_create', { resource: resource, records: data, primary_key: 'dataset_id' }, function(err) { if (err) console.log(err); console.log('All done'); }); </script> Python \u00b6 #!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' ckan = ckanapi.RemoteCKAN(remote, apikey) package = ckan.action.package_show(id='packagetest') resource = {\"package_id\": package['id'],\"format\": \"CSV\", \"name\": \"NameExample\"} newfields = [ {'id': 'dataset_id', 'type': 'text'}, {'id': 'indicator_id', 'type': 'text'}, {'id': 'region', 'type': 'text'}, {'id': 'period', 'type': 'int'}, {'id': 'value', 'type': 'float'} ] newRecords = [ { 'indicator_id': 'Population', 'dataset_id': 'acled', 'region': 'ITA', 'value': '5000000', 'period': '2016' } ] ckan.action.datastore_create(resource=resource, fields=newfields, records=newRecords, primary_key='dataset_id')","title":"Datastore_create"},{"location":"data/storage/datastore-create/#datastore_create","text":"","title":"Datastore_create"},{"location":"data/storage/datastore-create/#parameters","text":"resource_id (string) \u2013 resource id that the data is going to be stored against. force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource resource (dictionary) \u2013 resource dictionary that is passed to resource_create() . Use instead of resource_id (optional) aliases (list or comma separated string) \u2013 names for read only aliases of the resource. (optional) fields (list of dictionaries) \u2013 fields/columns and their extra metadata. (optional) records (list of dictionaries) \u2013 the data, e.g.: [{\"dob\": \"2005\", \"some_stuff\": [\"a\", \"b\"]}] (optional) primary_key (list or comma separated string) \u2013 fields that represent a unique key (optional) indexes (list or comma separated string) \u2013 indexes on table (optional)","title":"Parameters"},{"location":"data/storage/datastore-create/#javascript","text":"<script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var nfields = [ {'id': 'dataset_id', 'type': 'text'}, {'id': 'indicator_id', 'type': 'text'}, {'id': 'region', 'type': 'text'}, {'id': 'period', 'type': 'int'}, {'id': 'value', 'type': 'float'} ]; var data = [ { 'indicator_id': 'Population', 'dataset_id': 'acled', 'region': 'ITA', 'value': '5000000', 'period': '2016' } ]; var resource = { \"package_id\": \"packagetest\", \"format\": \"CSV\", \"name\": \"NameExample2\" }; client.action('datastore_create', { resource: resource, records: data, primary_key: 'dataset_id' }, function(err) { if (err) console.log(err); console.log('All done'); }); </script>","title":"Javascript"},{"location":"data/storage/datastore-create/#python","text":"#!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' ckan = ckanapi.RemoteCKAN(remote, apikey) package = ckan.action.package_show(id='packagetest') resource = {\"package_id\": package['id'],\"format\": \"CSV\", \"name\": \"NameExample\"} newfields = [ {'id': 'dataset_id', 'type': 'text'}, {'id': 'indicator_id', 'type': 'text'}, {'id': 'region', 'type': 'text'}, {'id': 'period', 'type': 'int'}, {'id': 'value', 'type': 'float'} ] newRecords = [ { 'indicator_id': 'Population', 'dataset_id': 'acled', 'region': 'ITA', 'value': '5000000', 'period': '2016' } ] ckan.action.datastore_create(resource=resource, fields=newfields, records=newRecords, primary_key='dataset_id')","title":"Python"},{"location":"data/storage/datastore-delete/","text":"Datastore_delete \u00b6 Parameters \u00b6 resource_id (string) \u2013 resource id that the data will be deleted from. (optional) force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource filters (dictionary) \u2013 filters to apply before deleting, e.g.: {\"name\": \"fred\"} . If missing delete whole table and all dependent views. (optional) Javascript \u00b6 <script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var resourceId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; var nfilters = {\"region\": 'KEN'}; var search = client.action('datastore_delete', { resource_id: resourceId, filters: nfilters, force: 'True' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script> Python \u00b6 #!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = 'c123ba85-41f9-4a04-80f5-a26368ba9204' ckan = ckanapi.RemoteCKAN(remote, apikey) filters = {\"region\": \"KEN\"} data = ckan.action.datastore_delete(resource_id=resource_id, filters=filters, force= True)","title":"Datastore_delete"},{"location":"data/storage/datastore-delete/#datastore_delete","text":"","title":"Datastore_delete"},{"location":"data/storage/datastore-delete/#parameters","text":"resource_id (string) \u2013 resource id that the data will be deleted from. (optional) force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource filters (dictionary) \u2013 filters to apply before deleting, e.g.: {\"name\": \"fred\"} . If missing delete whole table and all dependent views. (optional)","title":"Parameters"},{"location":"data/storage/datastore-delete/#javascript","text":"<script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var resourceId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; var nfilters = {\"region\": 'KEN'}; var search = client.action('datastore_delete', { resource_id: resourceId, filters: nfilters, force: 'True' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script>","title":"Javascript"},{"location":"data/storage/datastore-delete/#python","text":"#!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = 'c123ba85-41f9-4a04-80f5-a26368ba9204' ckan = ckanapi.RemoteCKAN(remote, apikey) filters = {\"region\": \"KEN\"} data = ckan.action.datastore_delete(resource_id=resource_id, filters=filters, force= True)","title":"Python"},{"location":"data/storage/datastore-upsert/","text":"Datastore_upsert \u00b6 Parameters \u00b6 resource_id (string) \u2013 resource id that the data is going to be stored under. force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource records (list of dictionaries) \u2013 the data, e.g.: [{\"dob\": \"2005\", \"some_stuff\": [\"a\",\"b\"]}] (optional) method (string) \u2013 the method to use to put the data into the datastore. Possible options are: \"upsert\" , \"insert\" , \"update\" (optional, default: \"upsert\" ) Methods \u00b6 upsert : Update if record with same key already exists, otherwise insert. Requires unique key. insert : Insert only. This method is faster that upsert, but will fail if any inserted record matches an existing one. Does not require a unique key. update : Update only. An exception will occur if the key that should be updated does not exist. Requires unique key. Javascript \u00b6 <script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var data = [ {'indicator_id': 'CHD.B.HUM.04.T6', 'dataset_id': 'acled', 'region': 'KEN', 'value': '50000000', 'period': '2016'} ]; packageId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; client.action('datastore_upsert', { resource_id: packageId, records: data, method: 'upsert', force: 'True' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script> Python \u00b6 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = '450f2c55-425f-4797-8d70-33b5729d1f1d' ckan = ckanapi.RemoteCKAN(remote, apikey) newRecord = [ {'indicator_id': 'CHD.B.HUM.04.T6', 'dataset_id': 'acled', 'region': 'KEN', 'value': '50000000', 'period': '2016'} ] ckan.action.datastore_upsert( resource_id=resource_id, method='upsert', records=newRecord, force=True)","title":"Datastore_upsert"},{"location":"data/storage/datastore-upsert/#datastore_upsert","text":"","title":"Datastore_upsert"},{"location":"data/storage/datastore-upsert/#parameters","text":"resource_id (string) \u2013 resource id that the data is going to be stored under. force (boolean (optional, default: false )) \u2013 set to true to edit a read-only resource records (list of dictionaries) \u2013 the data, e.g.: [{\"dob\": \"2005\", \"some_stuff\": [\"a\",\"b\"]}] (optional) method (string) \u2013 the method to use to put the data into the datastore. Possible options are: \"upsert\" , \"insert\" , \"update\" (optional, default: \"upsert\" )","title":"Parameters"},{"location":"data/storage/datastore-upsert/#methods","text":"upsert : Update if record with same key already exists, otherwise insert. Requires unique key. insert : Insert only. This method is faster that upsert, but will fail if any inserted record matches an existing one. Does not require a unique key. update : Update only. An exception will occur if the key that should be updated does not exist. Requires unique key.","title":"Methods"},{"location":"data/storage/datastore-upsert/#javascript","text":"<script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); var data = [ {'indicator_id': 'CHD.B.HUM.04.T6', 'dataset_id': 'acled', 'region': 'KEN', 'value': '50000000', 'period': '2016'} ]; packageId = '450f2c55-425f-4797-8d70-33b5729d1f1d'; client.action('datastore_upsert', { resource_id: packageId, records: data, method: 'upsert', force: 'True' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script>","title":"Javascript"},{"location":"data/storage/datastore-upsert/#python","text":"import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' resource_id = '450f2c55-425f-4797-8d70-33b5729d1f1d' ckan = ckanapi.RemoteCKAN(remote, apikey) newRecord = [ {'indicator_id': 'CHD.B.HUM.04.T6', 'dataset_id': 'acled', 'region': 'KEN', 'value': '50000000', 'period': '2016'} ] ckan.action.datastore_upsert( resource_id=resource_id, method='upsert', records=newRecord, force=True)","title":"Python"},{"location":"data/storage/package-create/","text":"Package_create \u00b6 Parameters \u00b6 name (string) \u2013 the name of the new dataset, must be between 2 and 100 characters long and contain only lowercase alphanumeric characters, - and _, e.g.: warandpeace title (string) \u2013 the title of the dataset (optional, default: same as name) author (string) \u2013 the name of the dataset\u2019s author (optional) author_email (string) \u2013 the email address of the dataset\u2019s author (optional) maintainer (string) \u2013 the name of the dataset\u2019s maintainer (optional) maintainer_email (string) \u2013 the email address of the dataset\u2019s maintainer (optional) license_id (license id string) \u2013 the id of the dataset\u2019s license, see license_list() for available values (optional) notes (string) \u2013 a description of the dataset (optional) url (string) \u2013 a URL for the dataset\u2019s source (optional) version (string, no longer than 100 characters) \u2013 (optional) state (string) \u2013 the current state of the dataset, e.g. \"active\" or \"deleted\" , only active datasets show up in search results and other lists of datasets, this parameter will be ignored if you are not authorized to change the state of the dataset (optional, default: \"active\" ) type (string) \u2013 the type of the dataset (optional), IDatasetForm plugins associate themselves with different dataset types and provide custom dataset handling behaviour for these types resources (list of resource dictionaries) \u2013 the dataset\u2019s resources, see resource_create() for the format of resource dictionaries (optional) tags (Array[Strings]) \u2013 list of tag dictionaries, see tag_create() for the format of tag dictionaries (optional) extras (Array[Objects]) \u2013 list of dataset extra dictionaries (optional), extras are arbitrary, metadata items that can be added to datasets, each extra dictionary should have keys: key (string) value (string) - e.g.: deleted relationships_as_object (list of relationship dictionaries) \u2013 see package_relationship_create() for the format of relationship dictionaries (optional) relationships_as_subject (list of relationship dictionaries) \u2013 see package_relationship_create() for the format of relationship dictionaries (optional) groups (list of dictionaries) \u2013 the groups to which the dataset belongs (optional), each group dictionary should have one or more of the following keys which identify an existing group: id (string) - the id of the group name (string) - the name of the group title (string) - the title of the group, to see which groups exist call group_list() owner_org (string) \u2013 the id of the dataset\u2019s owning organization, see organization_list() or organization_list_for_user() for available values (optional) Javascript \u00b6 <script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); client.action('package_create', { name: 'newtestsprova', owner_org: 'tests' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script> Python \u00b6 #!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' ckan = ckanapi.RemoteCKAN(remote, apikey) package = ckan.action.package_create(name='packagetest', owner_org='tests') R \u00b6 library('ckanr') ckanr_setup(url = \"http://giv-oct.uni-muenster.de:5000\", key = \"5df62ec6-5fa7-4e2f-838a-a7d30c6aca39\") # create a package (res <- package_create(\"newpackage\", owner_org='tests'))","title":"Package_create"},{"location":"data/storage/package-create/#package_create","text":"","title":"Package_create"},{"location":"data/storage/package-create/#parameters","text":"name (string) \u2013 the name of the new dataset, must be between 2 and 100 characters long and contain only lowercase alphanumeric characters, - and _, e.g.: warandpeace title (string) \u2013 the title of the dataset (optional, default: same as name) author (string) \u2013 the name of the dataset\u2019s author (optional) author_email (string) \u2013 the email address of the dataset\u2019s author (optional) maintainer (string) \u2013 the name of the dataset\u2019s maintainer (optional) maintainer_email (string) \u2013 the email address of the dataset\u2019s maintainer (optional) license_id (license id string) \u2013 the id of the dataset\u2019s license, see license_list() for available values (optional) notes (string) \u2013 a description of the dataset (optional) url (string) \u2013 a URL for the dataset\u2019s source (optional) version (string, no longer than 100 characters) \u2013 (optional) state (string) \u2013 the current state of the dataset, e.g. \"active\" or \"deleted\" , only active datasets show up in search results and other lists of datasets, this parameter will be ignored if you are not authorized to change the state of the dataset (optional, default: \"active\" ) type (string) \u2013 the type of the dataset (optional), IDatasetForm plugins associate themselves with different dataset types and provide custom dataset handling behaviour for these types resources (list of resource dictionaries) \u2013 the dataset\u2019s resources, see resource_create() for the format of resource dictionaries (optional) tags (Array[Strings]) \u2013 list of tag dictionaries, see tag_create() for the format of tag dictionaries (optional) extras (Array[Objects]) \u2013 list of dataset extra dictionaries (optional), extras are arbitrary, metadata items that can be added to datasets, each extra dictionary should have keys: key (string) value (string) - e.g.: deleted relationships_as_object (list of relationship dictionaries) \u2013 see package_relationship_create() for the format of relationship dictionaries (optional) relationships_as_subject (list of relationship dictionaries) \u2013 see package_relationship_create() for the format of relationship dictionaries (optional) groups (list of dictionaries) \u2013 the groups to which the dataset belongs (optional), each group dictionary should have one or more of the following keys which identify an existing group: id (string) - the id of the group name (string) - the name of the group title (string) - the title of the group, to see which groups exist call group_list() owner_org (string) \u2013 the id of the dataset\u2019s owning organization, see organization_list() or organization_list_for_user() for available values (optional)","title":"Parameters"},{"location":"data/storage/package-create/#javascript","text":"<script> var client = new CKAN.Client('http://giv-oct.uni-muenster.de:5000', '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39'); client.action('package_create', { name: 'newtestsprova', owner_org: 'tests' }, function(err) { if (err) console.log(err); console.log('All done'); }) </script>","title":"Javascript"},{"location":"data/storage/package-create/#python","text":"#!/usr/bin/env python2 import ckanapi remote = 'http://giv-oct.uni-muenster.de:5000' apikey = '5df62ec6-5fa7-4e2f-838a-a7d30c6aca39' ckan = ckanapi.RemoteCKAN(remote, apikey) package = ckan.action.package_create(name='packagetest', owner_org='tests')","title":"Python"},{"location":"data/storage/package-create/#r","text":"library('ckanr') ckanr_setup(url = \"http://giv-oct.uni-muenster.de:5000\", key = \"5df62ec6-5fa7-4e2f-838a-a7d30c6aca39\") # create a package (res <- package_create(\"newpackage\", owner_org='tests'))","title":"R"},{"location":"installations/bower/","text":"What is Bower? \u00b6 A package manager for the web (Source: http://bower.io , 2016-02-15) Linux/MacOS \u00b6 You need Nodejs to install Bower. Install Bower globally with the following command: sudo npm install bower -g Windows \u00b6 You need Nodejs to install Bower. Install Bower globally with the following command: npm install bower -g Install packages \u00b6 Install all dependecies (bower-packages) of a bower.json -file. Init \u00b6 bower init -> bower.json mkdir lib -> /public/lib nano .bowerrc Bowerrc-File: { \"directory\":\"lib\" } bower install jquery --save bower install bootstrap --save","title":"Bower"},{"location":"installations/bower/#what-is-bower","text":"A package manager for the web (Source: http://bower.io , 2016-02-15)","title":"What is Bower?"},{"location":"installations/bower/#linuxmacos","text":"You need Nodejs to install Bower. Install Bower globally with the following command: sudo npm install bower -g","title":"Linux/MacOS"},{"location":"installations/bower/#windows","text":"You need Nodejs to install Bower. Install Bower globally with the following command: npm install bower -g","title":"Windows"},{"location":"installations/bower/#install-packages","text":"Install all dependecies (bower-packages) of a bower.json -file.","title":"Install packages"},{"location":"installations/bower/#init","text":"bower init -> bower.json mkdir lib -> /public/lib nano .bowerrc Bowerrc-File: { \"directory\":\"lib\" } bower install jquery --save bower install bootstrap --save","title":"Init"},{"location":"installations/cd/","text":"What is Continuous Deployment/Delivery? \u00b6 Continuous delivery (CD) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time.[1] It aims at building, testing, and releasing software faster and more frequently. The approach helps reduce the cost, time, and risk of delivering changes by allowing for more incremental updates to applications in production. A straightforward and repeatable deployment process is important for continuous delivery. (Source: Wikipedia , 2016-03-21) Where can we use it? \u00b6 We use CD for building automatically our documentation on our Main-Server. The following steps shows how we used it for MkDocs, but you can use the same technique also for your application, service or program. Installation \u00b6 First create a Webhook on GitHub in the repository-settings with the following URL: http://giv-oct.uni-muenster.de:61440/github Login on the Main-Server and clone the repository of node-cd ATTENTION: There is already GEO-C-Version of the original node-cd -repository, so you can skip the steps which are marked with an [*] ! GEO-C-Version : git clone https://github.com/geo-c/node-cd.git [*] Original version : git clone https://github.com/A21z/node-cd.git Install all dependencies with the following command: sudo npm install [*] Update the file /home/webteam/node-cd/github.sh with the commands, which should run after a webhook-detection. For MkDocs we make a simple pull-request to download the latest files from our GitHub-repository and build the documentation: github.sh: cd /home/webteam/Dev-Corner/ && git pull && sudo mkdocs build --clean Make the file /home/webteam/node-cd/github.sh excecutable, and also excecutable by root-user! This is an important step, otherwise the commands can not be run: chmod u+s github.sh [*] Update the file /home/webteam/node-cd/config.js with the correct folder-path, so it should look like this: action: { exec: { github: '/home/webteam/node-cd/github.sh', bitbucket: './bitbucket.sh', contentful: './contentful.sh' } } Add a cron-job for automatic start, when the Main-Server reboots with the command sudo nano /etc/crontab and add the following lines: # Automatic-Deployment-Server @reboot root node /home/webteam/node-cd/src/index.js Finally restart the Main-Server, so that the Continuous Delivery System starts listening for commits on GitHub. sudo shutdown -r 0 Second Listener \u00b6 If you want to checkout more than 1 repository, create in your new repository a new Webhook with a new portnumber, e.g. http://giv-oct.uni-muenster.de:61441/github Clone the node-cd -repository again on the Main-Server Follow the same steps like above, but before starting the server, change the portnumber in the /home/webteam/node-cd_2/config.js -file: var Private = { server: {port: '61441'}, ... } Add a second cron-job and reboot again","title":"Continuous Delivery"},{"location":"installations/cd/#what-is-continuous-deploymentdelivery","text":"Continuous delivery (CD) is a software engineering approach in which teams produce software in short cycles, ensuring that the software can be reliably released at any time.[1] It aims at building, testing, and releasing software faster and more frequently. The approach helps reduce the cost, time, and risk of delivering changes by allowing for more incremental updates to applications in production. A straightforward and repeatable deployment process is important for continuous delivery. (Source: Wikipedia , 2016-03-21)","title":"What is Continuous Deployment/Delivery?"},{"location":"installations/cd/#where-can-we-use-it","text":"We use CD for building automatically our documentation on our Main-Server. The following steps shows how we used it for MkDocs, but you can use the same technique also for your application, service or program.","title":"Where can we use it?"},{"location":"installations/cd/#installation","text":"First create a Webhook on GitHub in the repository-settings with the following URL: http://giv-oct.uni-muenster.de:61440/github Login on the Main-Server and clone the repository of node-cd ATTENTION: There is already GEO-C-Version of the original node-cd -repository, so you can skip the steps which are marked with an [*] ! GEO-C-Version : git clone https://github.com/geo-c/node-cd.git [*] Original version : git clone https://github.com/A21z/node-cd.git Install all dependencies with the following command: sudo npm install [*] Update the file /home/webteam/node-cd/github.sh with the commands, which should run after a webhook-detection. For MkDocs we make a simple pull-request to download the latest files from our GitHub-repository and build the documentation: github.sh: cd /home/webteam/Dev-Corner/ && git pull && sudo mkdocs build --clean Make the file /home/webteam/node-cd/github.sh excecutable, and also excecutable by root-user! This is an important step, otherwise the commands can not be run: chmod u+s github.sh [*] Update the file /home/webteam/node-cd/config.js with the correct folder-path, so it should look like this: action: { exec: { github: '/home/webteam/node-cd/github.sh', bitbucket: './bitbucket.sh', contentful: './contentful.sh' } } Add a cron-job for automatic start, when the Main-Server reboots with the command sudo nano /etc/crontab and add the following lines: # Automatic-Deployment-Server @reboot root node /home/webteam/node-cd/src/index.js Finally restart the Main-Server, so that the Continuous Delivery System starts listening for commits on GitHub. sudo shutdown -r 0","title":"Installation"},{"location":"installations/cd/#second-listener","text":"If you want to checkout more than 1 repository, create in your new repository a new Webhook with a new portnumber, e.g. http://giv-oct.uni-muenster.de:61441/github Clone the node-cd -repository again on the Main-Server Follow the same steps like above, but before starting the server, change the portnumber in the /home/webteam/node-cd_2/config.js -file: var Private = { server: {port: '61441'}, ... } Add a second cron-job and reboot again","title":"Second Listener"},{"location":"installations/mkdocs/","text":"What is MkDocs? \u00b6 MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. (Source: MkDocs , 2016-03-06) Installation \u00b6 You need Python (2.7.2) and the Python Package Index (1.5.2) to install and build the documentation. Please make sure that your operating-system provides it, otherwise please install Python before continuing: python --version pip --version This documentation is written in Markdown-Syntax. If you are not familiar with Markdown, you can find some nice Cheat cheets here: https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet https://daringfireball.net/projects/markdown/ Install MkDocs with the following command: pip install mkdocs Run MkDocs \u00b6 If you want to add new content to this documentation, you can use a local repository on your system or edit the pages directly on GitHub. First clone this repository to your local-repository git clone https://github.com/geo-c/Dev-Corner.git MkDocs comes with a build-in-server, which means that all .md -files inside the /docs -folder will be generated into .html -files on-the-fly. This is very useful to see your edited files live in your browser To start the build-in-server enter the Dev-Corner/ -folder of your local repository and run the following command: mkdocs serve Open a new tab in your browser and go to http://127.0.0.1:8000/ Contribution \u00b6 If you want to add new pages to this documentation, create a new .md -Files in folder: docs/ Hint : If you want to add sections, create a new folder, like this: docs/NewSection and create your new .md -files in this folder Before building, don't forget to add your new page(s) and sections in the mkdocs.yml -file. Please find an example at the end of this page: NewSection and newSinglePage.md - Home: index.md - Installations: - Nodejs: installations/nodejs.md - Bower: installations/bower.md - Data: - Collection: data/collection.md - Storage: data/storage.md - Retrieval: data/retrieval.md - Analysis: data/analysis.md - Visualization: data/visualization.md - About: - Licenses: about/licenses.md - Repositories: about/repositories.md - Contributers: about/contributers.md - NewSection: - newPage: newSection/newPage.md - newSinglePage.md: newSinglePage.md If you are not familiar with Markdown, please find some Cheat Cheets above. It is also possible to use HTML-tags inside the Markdown-file, for example a embedded video from Youtube: ## Video from Youtube <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LRLQE2N0DKc\" frameborder=\"0\" allowfullscreen></iframe> If you have finish your work, please make sure, that there are no errors in the logs of the build-in-server. Please commit then your edited files to GitHub. Our Main-Server has a cron-job, which will add your files automatically everyday at midnight and convert them into HTML-files. Build-process \u00b6 As already mentioned, our Main-Server has a cron-job, which will clone the repository automatically everyday at midnight and render the documentation from Markdown to HTML. It is also possible to build the HTML-files from your local repository. Before you build it, change the destination inside the mkdocs.yml -File: Old: # Local #site_dir: site # Server site_dir: /var/www/html/dev-corner New: # Local site_dir: site # Server #site_dir: /var/www/html/dev-corner Attention : Please undo this before you commit your mkdocs.yml -file to GitHub!! Build documentation with the following command: mkdocs build Attention : If some problems occur during the build-process, you can also try to re-build the documentation with the following command: mkdocs build --clean The clean-build is useful, if you removed some pages inside the YAML-File, so that the old pages All Markdown-Files are now converted to HTML-files into the site/ -folder. To see your changes your site/ -folder should be in a Webserver, like an Apache or a Nodejs-Webserver. Otherwise not all functions are working, e.g. the search-function. Because MkDocs comes already with an build-in-server, it is highly recommended to use the command mkdocs serve and mkdocs build only on your published server. For more information about MkDocs, please have a look at http://www.mkdocs.org/ .","title":"MkDocs"},{"location":"installations/mkdocs/#what-is-mkdocs","text":"MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. (Source: MkDocs , 2016-03-06)","title":"What is MkDocs?"},{"location":"installations/mkdocs/#installation","text":"You need Python (2.7.2) and the Python Package Index (1.5.2) to install and build the documentation. Please make sure that your operating-system provides it, otherwise please install Python before continuing: python --version pip --version This documentation is written in Markdown-Syntax. If you are not familiar with Markdown, you can find some nice Cheat cheets here: https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet https://daringfireball.net/projects/markdown/ Install MkDocs with the following command: pip install mkdocs","title":"Installation"},{"location":"installations/mkdocs/#run-mkdocs","text":"If you want to add new content to this documentation, you can use a local repository on your system or edit the pages directly on GitHub. First clone this repository to your local-repository git clone https://github.com/geo-c/Dev-Corner.git MkDocs comes with a build-in-server, which means that all .md -files inside the /docs -folder will be generated into .html -files on-the-fly. This is very useful to see your edited files live in your browser To start the build-in-server enter the Dev-Corner/ -folder of your local repository and run the following command: mkdocs serve Open a new tab in your browser and go to http://127.0.0.1:8000/","title":"Run MkDocs"},{"location":"installations/mkdocs/#contribution","text":"If you want to add new pages to this documentation, create a new .md -Files in folder: docs/ Hint : If you want to add sections, create a new folder, like this: docs/NewSection and create your new .md -files in this folder Before building, don't forget to add your new page(s) and sections in the mkdocs.yml -file. Please find an example at the end of this page: NewSection and newSinglePage.md - Home: index.md - Installations: - Nodejs: installations/nodejs.md - Bower: installations/bower.md - Data: - Collection: data/collection.md - Storage: data/storage.md - Retrieval: data/retrieval.md - Analysis: data/analysis.md - Visualization: data/visualization.md - About: - Licenses: about/licenses.md - Repositories: about/repositories.md - Contributers: about/contributers.md - NewSection: - newPage: newSection/newPage.md - newSinglePage.md: newSinglePage.md If you are not familiar with Markdown, please find some Cheat Cheets above. It is also possible to use HTML-tags inside the Markdown-file, for example a embedded video from Youtube: ## Video from Youtube <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/LRLQE2N0DKc\" frameborder=\"0\" allowfullscreen></iframe> If you have finish your work, please make sure, that there are no errors in the logs of the build-in-server. Please commit then your edited files to GitHub. Our Main-Server has a cron-job, which will add your files automatically everyday at midnight and convert them into HTML-files.","title":"Contribution"},{"location":"installations/mkdocs/#build-process","text":"As already mentioned, our Main-Server has a cron-job, which will clone the repository automatically everyday at midnight and render the documentation from Markdown to HTML. It is also possible to build the HTML-files from your local repository. Before you build it, change the destination inside the mkdocs.yml -File: Old: # Local #site_dir: site # Server site_dir: /var/www/html/dev-corner New: # Local site_dir: site # Server #site_dir: /var/www/html/dev-corner Attention : Please undo this before you commit your mkdocs.yml -file to GitHub!! Build documentation with the following command: mkdocs build Attention : If some problems occur during the build-process, you can also try to re-build the documentation with the following command: mkdocs build --clean The clean-build is useful, if you removed some pages inside the YAML-File, so that the old pages All Markdown-Files are now converted to HTML-files into the site/ -folder. To see your changes your site/ -folder should be in a Webserver, like an Apache or a Nodejs-Webserver. Otherwise not all functions are working, e.g. the search-function. Because MkDocs comes already with an build-in-server, it is highly recommended to use the command mkdocs serve and mkdocs build only on your published server. For more information about MkDocs, please have a look at http://www.mkdocs.org/ .","title":"Build-process"},{"location":"installations/nodejs/","text":"What is Nodejs? \u00b6 Node.js\u00ae is a JavaScript runtime built on Chrome's V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js' package ecosystem, npm, is the largest ecosystem of open source libraries in the world. (Source: https://nodejs.org/en/ , 2016-02-15) Linux \u00b6 For Ubuntu add the following link to you package-list: curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash - Install nodejs with the following command: sudo apt-get install -y nodejs For other distributions go to https://nodejs.org/en/download/package-manager/ and install the latest stable version (LTS-verion is recommend)) Open the commandline and update the node-package-manager: sudo npm install npm -g MacOS \u00b6 Go to https://nodejs.org/en/ and download the latest stable version (LTS-verion is recommend) Install the package Open the terminal and update the node-package-manager: sudo npm install npm -g Windows \u00b6 Go to https://nodejs.org/en/ and install Open the Windows-Shell (cmd) and update the node-package-manager: npm install npm -g Install packages \u00b6 Install all dependecies (node-packages) of a package.json -file. Init \u00b6 Create a package.json : To-Do","title":"Nodejs"},{"location":"installations/nodejs/#what-is-nodejs","text":"Node.js\u00ae is a JavaScript runtime built on Chrome's V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js' package ecosystem, npm, is the largest ecosystem of open source libraries in the world. (Source: https://nodejs.org/en/ , 2016-02-15)","title":"What is Nodejs?"},{"location":"installations/nodejs/#linux","text":"For Ubuntu add the following link to you package-list: curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash - Install nodejs with the following command: sudo apt-get install -y nodejs For other distributions go to https://nodejs.org/en/download/package-manager/ and install the latest stable version (LTS-verion is recommend)) Open the commandline and update the node-package-manager: sudo npm install npm -g","title":"Linux"},{"location":"installations/nodejs/#macos","text":"Go to https://nodejs.org/en/ and download the latest stable version (LTS-verion is recommend) Install the package Open the terminal and update the node-package-manager: sudo npm install npm -g","title":"MacOS"},{"location":"installations/nodejs/#windows","text":"Go to https://nodejs.org/en/ and install Open the Windows-Shell (cmd) and update the node-package-manager: npm install npm -g","title":"Windows"},{"location":"installations/nodejs/#install-packages","text":"Install all dependecies (node-packages) of a package.json -file.","title":"Install packages"},{"location":"installations/nodejs/#init","text":"Create a package.json : To-Do","title":"Init"}]}